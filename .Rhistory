nnpcomp <- prcomp(nndf)
nppcomp$rotation
nnpcomp <- prcomp(nndf)
nppcomp$rotation
nnpcomp <- prcomp(nndf)
nppcomp$rotation
nnpcomp <- prcomp(nndf)
nppcomp
nnpcomp <- prcomp(nndf)
nppcomp
nnpcomp <- prcomp(nndf)
nnpcomp$rotation
# The package "ezids" (EZ Intro to Data Science) includes a lot of the helper functions we developed for the course.
# Some of the frequently used functions are loadPkg(), xkabledply(), xkablesummary(), uzscale(), etc.
library(ezids)
# some of common options (and the defaults) are:
# include=T, eval=T, echo=T, results='hide'/'asis'/'markup',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right',
# knitr::opts_chunk$set(warning = F, results = "markup", message = F)
knitr::opts_chunk$set(warning = F, results = "hide", message = F)
options(scientific=T, digits = 3)
# options(scipen=9, digits = 3)
# ‘scipen’: integer. A penalty to be applied when deciding to print numeric values in fixed or exponential notation.  Positive values bias towards fixed and negative towards scientific notation: fixed notation will be preferred unless it is more than ‘scipen’ digits wider.
# use scipen=999 to prevent scientific notation at all times
# This example is from the Intro to Statistical Learning Lab which uses USArrets data.
#Below creates a character vector from the first column in the data.frame
# states <- row.names(USArrests)
#We now want to glance at our data, to try to understand the differences between the variables
USArrestsCentroid <- apply(USArrests , 2, mean)
xkabledply( as.table(USArrestsCentroid), wide = TRUE, title = "Centroid for USArrests" )
#We can see that that the average between the variables is quite high
USArrestsSds <- apply(USArrests , 2, var)
xkabledply( as.table(USArrestsSds), wide = TRUE, title = "Std devs for USArrests" )
xkablesummary(USArrests, title = "Five number summaries for USArrests")
#Find the correlation matrix
xkabledply( cor(USArrests), title = "correlation matrix for USArrests" )
#And the covariance matrix
xkabledply( cov(USArrests), title = "covariance matrix for USArrests" )
#compare to the matrices after standardization
USArrestscale = data.frame(scale(USArrests))
xkabledply( cor(USArrestscale), title = "correlation matrix for USArrestscale" )
xkabledply( cov(USArrestscale), title = "covariance matrix for USArrestscale"  )
pr.out =prcomp(USArrests , scale =TRUE) # center=TRUE is the default
pr.out.ns =prcomp(USArrests , scale =FALSE) # this is centered, un-normalized data, just for comparison.
pr.out.nsnc =prcomp(USArrests , scale =FALSE, center = FALSE) # this is neither centered nor scaled.
#Here are the "loading" vector for the PCA components
print("Case: z-score/scaled")
summary(pr.out)
pr.out$rotation
print("Case: not scaled")
summary(pr.out.ns)
pr.out.ns$rotation
print("Case: not scaled nor centered")
summary(pr.out.nsnc)
pr.out.nsnc$rotation
nnpcomp <- prcomp(nndf)
summary(nnpcomp)
nnpcomp$rotation
biplot (nnpcomp, c(1,2), scale=0)
biplot (nnpcomp, c(1,2), scale=0)
biplot( nnpcomp, c(2,3), scale=0)
biplot( nnpcomp, c(3,4), scale=0)
biplot (nnpcomp, c(4,5), scale=0)
biplot( nnpcomp, c(5,6), scale=0)
# The package "ezids" (EZ Intro to Data Science) includes a lot of the helper functions we developed for the course.
# Some of the frequently used functions are loadPkg(), xkabledply(), xkablesummary(), uzscale(), etc.
library(ezids)
# some of common options (and the defaults) are:
# include=T, eval=T, echo=T, results='hide'/'asis'/'markup',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right',
# knitr::opts_chunk$set(warning = F, results = "markup", message = F)
knitr::opts_chunk$set(warning = F, results = "hide", message = F)
options(scientific=T, digits = 3)
# options(scipen=9, digits = 3)
# ‘scipen’: integer. A penalty to be applied when deciding to print numeric values in fixed or exponential notation.  Positive values bias towards fixed and negative towards scientific notation: fixed notation will be preferred unless it is more than ‘scipen’ digits wider.
# use scipen=999 to prevent scientific notation at all times
# This example is from the Intro to Statistical Learning Lab which uses USArrets data.
#Below creates a character vector from the first column in the data.frame
# states <- row.names(USArrests)
#We now want to glance at our data, to try to understand the differences between the variables
USArrestsCentroid <- apply(USArrests , 2, mean)
xkabledply( as.table(USArrestsCentroid), wide = TRUE, title = "Centroid for USArrests" )
#We can see that that the average between the variables is quite high
USArrestsSds <- apply(USArrests , 2, var)
xkabledply( as.table(USArrestsSds), wide = TRUE, title = "Std devs for USArrests" )
xkablesummary(USArrests, title = "Five number summaries for USArrests")
#Find the correlation matrix
xkabledply( cor(USArrests), title = "correlation matrix for USArrests" )
#And the covariance matrix
xkabledply( cov(USArrests), title = "covariance matrix for USArrests" )
#compare to the matrices after standardization
USArrestscale = data.frame(scale(USArrests))
xkabledply( cor(USArrestscale), title = "correlation matrix for USArrestscale" )
xkabledply( cov(USArrestscale), title = "covariance matrix for USArrestscale"  )
pr.out =prcomp(USArrests , scale =TRUE) # center=TRUE is the default
pr.out.ns =prcomp(USArrests , scale =FALSE) # this is centered, un-normalized data, just for comparison.
pr.out.nsnc =prcomp(USArrests , scale =FALSE, center = FALSE) # this is neither centered nor scaled.
#Here are the "loading" vector for the PCA components
print("Case: z-score/scaled")
summary(pr.out)
pr.out$rotation
print("Case: not scaled")
summary(pr.out.ns)
pr.out.ns$rotation
print("Case: not scaled nor centered")
summary(pr.out.nsnc)
pr.out.nsnc$rotation
print("USArrestsCentroid:")
USArrestsCentroid
print("Normalized USArrestsCentroid:")
USArrestsCentroid / sqrt(sum(USArrestsCentroid^2))
#####
# biplot(pr.out.ns, scale = 1)
biplot(pr.out, scale = 0) # scale = 1 is the default, which will scale the loadings by 10^1, and the PC component values by 10^-1.
USArrests.pc = PCAxform(USArrests,FALSE)
print("Case: not scaled")
summary(USArrests.pc)
cov(USArrests.pc)
cor(USArrests.pc)
USArrests.z.pc = PCAxform(USArrests,TRUE)
print("Case: z-score/scaled")
xkablesummary(USArrests.z.pc)
cov(USArrests.z.pc)
cor(USArrests.z.pc)
#Let us plot the cumulation of variance using the sd
pr.var <- (pr.out$sdev^2)
pve <- pr.var/sum(pr.var)
plot(cumsum(pve), xlab="Principal Component (standardized)", ylab ="Cumulative Proportion of Variance Explained",ylim=c(0,1),type="b")
pr.var.nc <- (pr.out.ns$sdev^2)
pve.nc <- pr.var.nc/sum(pr.var.nc)
plot(cumsum(pve.nc), xlab="Principal Component (non-standardized)", ylab ="Cumulative Proportion of Variance Explained",ylim=c(0,1),type="b")
biplot(pr.out,2:3, scale =0)
biplot(pr.out.ns,2:3, scale =0)
biplot(pr.out,3:4, scale =0)
biplot(pr.out.ns,3:4, scale =0)
# some of common options (and the defaults) are:
# include=T, eval=T, echo=T, results='hide'/'asis'/'markup',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right',
library(ezids)
# knitr::opts_chunk$set(warning = F, results = "markup", message = F)
knitr::opts_chunk$set(warning = F, results = "hide", message = F, echo = F)
options(scientific=T, digits = 3)
# options(scipen=9, digits = 3)
# ‘scipen’: integer. A penalty to be applied when deciding to print numeric values in fixed or exponential notation.  Positive values bias towards fixed and negative towards scientific notation: fixed notation will be preferred unless it is more than ‘scipen’ digits wider.
# use scipen=999 to prevent scientific notation at all times
datage < dat
# some of common options (and the defaults) are:
# include=T, eval=T, echo=T, results='hide'/'asis'/'markup',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right',
library(ezids)
# knitr::opts_chunk$set(warning = F, results = "markup", message = F)
knitr::opts_chunk$set(warning = F, results = "hide", message = F, echo = F)
options(scientific=T, digits = 3)
# options(scipen=9, digits = 3)
# ‘scipen’: integer. A penalty to be applied when deciding to print numeric values in fixed or exponential notation.  Positive values bias towards fixed and negative towards scientific notation: fixed notation will be preferred unless it is more than ‘scipen’ digits wider.
# use scipen=999 to prevent scientific notation at all times
library("corrplot")
library("ezids")
library("gtsummary")
library('ggridges')
library('viridis')
library('wesanderson')
library('gridExtra')
library('leaps')
library('vtable')
## Loading data
data = read.csv('datafile.csv')
initialrows = nrow(data)
data$AdoptionSpeed <- factor(data$AdoptionSpeed, order=T, levels = c(0,1,2,3,4))
# converting the data types we want - categorical
data$Type = as.factor(data$Type)
data$MaturitySize = as.factor(data$MaturitySize)
data$FurLength = as.factor(data$FurLength)
data$Vaccinated = as.factor(data$Vaccinated)
data$Gender = as.factor(data$Gender)
# Only looking at profiles with 1 animal
data = subset(data, data$Quantity == 1)
data = subset(data, ! data$AdoptionSpeed == 4)
# Only pulling the columns we want to look at
dat = data[c('Type', 'Age', 'Gender', 'MaturitySize', 'FurLength', 'Vaccinated', 'PhotoAmt','VideoAmt', 'AdoptionSpeed')]
summary(dat)
# Adding random values
#dat$ASnum = NaN
#dat$ASnum[dat$AdoptionSpeed == 0] = 0
#dat$ASnum[dat$AdoptionSpeed == 1] = floor(runif(sum(dat$AdoptionSpeed == 1), 1, 8))
#dat$ASnum[dat$AdoptionSpeed == 2] = floor(runif(sum(dat$AdoptionSpeed == 2), 8, 31))
#dat$ASnum[dat$AdoptionSpeed == 3] = floor(runif(sum(dat$AdoptionSpeed == 3), 31, 91))
#dat$ASnum[dat$AdoptionSpeed == 4] = 100 -- this line isn't necessary because we exclude animals that have this adoption speed
summary(dat)
datclean = dat[, c('Age', 'Gender', 'MaturitySize', 'FurLength', 'Vaccinated', 'PhotoAmt', 'VideoAmt', 'AdoptionSpeed')]
datclean$y = dat[, c('Type')]
loadPkg("bestglm")
res.bestglm <- bestglm(Xy = datclean, family = binomial,
IC = "AIC",                 # Information criteria for
method = "exhaustive")
summary(res.bestglm)
res.bestglm$BestModels
summary(res.bestglm$BestModels)
unloadPkg("bestglm")
unloadPkg("leaps") # leaps is required by bestglm, thus cannot be unloaded before bestglm
typeLogit <- glm(Type ~ Age + Gender + MaturitySize + FurLength + Vaccinated + AdoptionSpeed + PhotoAmt, data = dat, family = "binomial")
xkabledply(typeLogit, title = paste("Logistic Regression :", format(formula(typeLogit)) ))
loadPkg("ResourceSelection") # function hoslem.test( ) for logit model evaluation
typeHoslem = hoslem.test(dat$Type, fitted(typeLogit)) # Hosmer and Lemeshow test, a chi-squared test
typeHoslem
unloadPkg("ResourceSelection") # function hoslem.test( ) for logit model evaluation
loadPkg("pROC") # receiver operating characteristic curve, gives the diagnostic ability of a binary classifier system as its discrimination threshold is varied. The curve is on sensitivity/recall/true-positive-rate vs false_alarm/false-positive-rate/fall-out.
prob=predict(typeLogit, type = "response" )
dat$prob=prob
h <- roc(Type~prob, data=dat)
plot(h)
auc(h)
loadPkg("pscl") # use pR2( ) function to calculate McFadden statistics for model eval
typePR = pR2(typeLogit)
typePR
unloadPkg("pscl")
datage < dat
datage <- dat
datage$puppy = NaN
datage$puppy[datage$Age <= 3] = 1
datage$puppy[datage$Age > 3] = 0
datage$puppy = as.factor(datage$puppy)
puppies = subset(datage, datage$puppy == 1)
older = subset(datage, datage$puppy ==0)
puppy_proportion = nrow(puppies) * 100/nrow(dat)
View(datage)
View(dat)
datage <- dat[ ,c('Age', 'Gender', 'MaturitySize', 'FurLength', 'Vaccinated', 'PhotoAmt', 'VideoAmt', 'AdoptionSpeed') ]
datage$puppy = NaN
datage$puppy[datage$Age <= 3] = 1
datage$puppy[datage$Age > 3] = 0
datage$puppy = as.factor(datage$puppy)
puppies = subset(datage, datage$puppy == 1)
older = subset(datage, datage$puppy ==0)
puppy_proportion = nrow(puppies) * 100/nrow(dat)
datage <- dat[ ,c('Type','Gender', 'MaturitySize', 'FurLength', 'Vaccinated', 'PhotoAmt', 'VideoAmt', 'AdoptionSpeed') ]
datage$puppy = NaN
datage$puppy[dat$Age <= 3] = 1
datage$puppy[dat$Age > 3] = 0
datage$puppy = as.factor(datage$puppy)
puppies = subset(datage, datage$puppy == 1)
older = subset(datage, datage$puppy ==0)
puppy_proportion = nrow(puppies) * 100/nrow(dat)
# some of common options (and the defaults) are:
# include=T, eval=T, echo=T, results='hide'/'asis'/'markup',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right',
library(ezids)
# knitr::opts_chunk$set(warning = F, results = "markup", message = F)
knitr::opts_chunk$set(warning = F, results = "hide", message = F, echo = F)
options(scientific=T, digits = 3)
# options(scipen=9, digits = 3)
# ‘scipen’: integer. A penalty to be applied when deciding to print numeric values in fixed or exponential notation.  Positive values bias towards fixed and negative towards scientific notation: fixed notation will be preferred unless it is more than ‘scipen’ digits wider.
# use scipen=999 to prevent scientific notation at all times
library("corrplot")
library("ezids")
library("gtsummary")
library('ggridges')
library('viridis')
library('wesanderson')
library('gridExtra')
library('leaps')
library('vtable')
## Loading data
data = read.csv('datafile.csv')
initialrows = nrow(data)
data$AdoptionSpeed <- factor(data$AdoptionSpeed, order=T, levels = c(0,1,2,3,4))
# converting the data types we want - categorical
data$Type = as.factor(data$Type)
data$MaturitySize = as.factor(data$MaturitySize)
data$FurLength = as.factor(data$FurLength)
data$Vaccinated = as.factor(data$Vaccinated)
data$Gender = as.factor(data$Gender)
# Only looking at profiles with 1 animal
data = subset(data, data$Quantity == 1)
data = subset(data, ! data$AdoptionSpeed == 4)
# Only pulling the columns we want to look at
dat = data[c('Type', 'Age', 'Gender', 'MaturitySize', 'FurLength', 'Vaccinated', 'PhotoAmt','VideoAmt', 'AdoptionSpeed')]
summary(dat)
# Adding random values
#dat$ASnum = NaN
#dat$ASnum[dat$AdoptionSpeed == 0] = 0
#dat$ASnum[dat$AdoptionSpeed == 1] = floor(runif(sum(dat$AdoptionSpeed == 1), 1, 8))
#dat$ASnum[dat$AdoptionSpeed == 2] = floor(runif(sum(dat$AdoptionSpeed == 2), 8, 31))
#dat$ASnum[dat$AdoptionSpeed == 3] = floor(runif(sum(dat$AdoptionSpeed == 3), 31, 91))
#dat$ASnum[dat$AdoptionSpeed == 4] = 100 -- this line isn't necessary because we exclude animals that have this adoption speed
summary(dat)
datclean = dat[, c('Age', 'Gender', 'MaturitySize', 'FurLength', 'Vaccinated', 'PhotoAmt', 'VideoAmt', 'AdoptionSpeed')]
datclean$y = dat[, c('Type')]
loadPkg("bestglm")
res.bestglm <- bestglm(Xy = datclean, family = binomial,
IC = "AIC",                 # Information criteria for
method = "exhaustive")
summary(res.bestglm)
res.bestglm$BestModels
summary(res.bestglm$BestModels)
unloadPkg("bestglm")
unloadPkg("leaps") # leaps is required by bestglm, thus cannot be unloaded before bestglm
typeLogit <- glm(Type ~ Age + Gender + MaturitySize + FurLength + Vaccinated + AdoptionSpeed + PhotoAmt, data = dat, family = "binomial")
xkabledply(typeLogit, title = paste("Logistic Regression :", format(formula(typeLogit)) ))
loadPkg("ResourceSelection") # function hoslem.test( ) for logit model evaluation
typeHoslem = hoslem.test(dat$Type, fitted(typeLogit)) # Hosmer and Lemeshow test, a chi-squared test
typeHoslem
unloadPkg("ResourceSelection") # function hoslem.test( ) for logit model evaluation
loadPkg("pROC") # receiver operating characteristic curve, gives the diagnostic ability of a binary classifier system as its discrimination threshold is varied. The curve is on sensitivity/recall/true-positive-rate vs false_alarm/false-positive-rate/fall-out.
prob=predict(typeLogit, type = "response" )
dat$prob=prob
h <- roc(Type~prob, data=dat)
plot(h)
auc(h)
loadPkg("pscl") # use pR2( ) function to calculate McFadden statistics for model eval
typePR = pR2(typeLogit)
typePR
unloadPkg("pscl")
datage <- dat[ ,c('Type','Gender', 'MaturitySize', 'FurLength', 'Vaccinated', 'PhotoAmt', 'VideoAmt', 'AdoptionSpeed') ]
datage$puppy = NaN
datage$puppy[dat$Age <= 3] = 1
datage$puppy[dat$Age > 3] = 0
datage$puppy = as.factor(datage$puppy)
puppies = subset(datage, datage$puppy == 1)
older = subset(datage, datage$puppy ==0)
puppy_proportion = nrow(puppies) * 100/nrow(dat)
# some of common options (and the defaults) are:
# include=T, eval=T, echo=T, results='hide'/'asis'/'markup',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right',
library(ezids)
# knitr::opts_chunk$set(warning = F, results = "markup", message = F)
knitr::opts_chunk$set(warning = F, results = "hide", message = F, echo = F)
options(scientific=T, digits = 3)
# options(scipen=9, digits = 3)
# ‘scipen’: integer. A penalty to be applied when deciding to print numeric values in fixed or exponential notation.  Positive values bias towards fixed and negative towards scientific notation: fixed notation will be preferred unless it is more than ‘scipen’ digits wider.
# use scipen=999 to prevent scientific notation at all times
library("corrplot")
library("ezids")
library("gtsummary")
library('ggridges')
library('viridis')
library('wesanderson')
library('gridExtra')
library('leaps')
library('vtable')
## Loading data
data = read.csv('datafile.csv')
initialrows = nrow(data)
data$AdoptionSpeed <- factor(data$AdoptionSpeed, order=T, levels = c(0,1,2,3,4))
# converting the data types we want - categorical
data$Type = as.factor(data$Type)
data$MaturitySize = as.factor(data$MaturitySize)
data$FurLength = as.factor(data$FurLength)
data$Vaccinated = as.factor(data$Vaccinated)
data$Gender = as.factor(data$Gender)
# Only looking at profiles with 1 animal
data = subset(data, data$Quantity == 1)
data = subset(data, ! data$AdoptionSpeed == 4)
# Only pulling the columns we want to look at
dat = data[c('Type', 'Age', 'Gender', 'MaturitySize', 'FurLength', 'Vaccinated', 'PhotoAmt','VideoAmt', 'AdoptionSpeed')]
summary(dat)
# Adding random values
#dat$ASnum = NaN
#dat$ASnum[dat$AdoptionSpeed == 0] = 0
#dat$ASnum[dat$AdoptionSpeed == 1] = floor(runif(sum(dat$AdoptionSpeed == 1), 1, 8))
#dat$ASnum[dat$AdoptionSpeed == 2] = floor(runif(sum(dat$AdoptionSpeed == 2), 8, 31))
#dat$ASnum[dat$AdoptionSpeed == 3] = floor(runif(sum(dat$AdoptionSpeed == 3), 31, 91))
#dat$ASnum[dat$AdoptionSpeed == 4] = 100 -- this line isn't necessary because we exclude animals that have this adoption speed
summary(dat)
datclean = dat[, c('Age', 'Gender', 'MaturitySize', 'FurLength', 'Vaccinated', 'PhotoAmt', 'VideoAmt', 'AdoptionSpeed')]
datclean$y = dat[, c('Type')]
loadPkg("bestglm")
res.bestglm <- bestglm(Xy = datclean, family = binomial,
IC = "AIC",                 # Information criteria for
method = "exhaustive")
summary(res.bestglm)
res.bestglm$BestModels
summary(res.bestglm$BestModels)
unloadPkg("bestglm")
unloadPkg("leaps") # leaps is required by bestglm, thus cannot be unloaded before bestglm
typeLogit <- glm(Type ~ Age + Gender + MaturitySize + FurLength + Vaccinated + AdoptionSpeed + PhotoAmt, data = dat, family = "binomial")
xkabledply(typeLogit, title = paste("Logistic Regression :", format(formula(typeLogit)) ))
loadPkg("ResourceSelection") # function hoslem.test( ) for logit model evaluation
typeHoslem = hoslem.test(dat$Type, fitted(typeLogit)) # Hosmer and Lemeshow test, a chi-squared test
typeHoslem
unloadPkg("ResourceSelection") # function hoslem.test( ) for logit model evaluation
loadPkg("pROC") # receiver operating characteristic curve, gives the diagnostic ability of a binary classifier system as its discrimination threshold is varied. The curve is on sensitivity/recall/true-positive-rate vs false_alarm/false-positive-rate/fall-out.
prob=predict(typeLogit, type = "response" )
dat$prob=prob
h <- roc(Type~prob, data=dat)
plot(h)
auc(h)
loadPkg("pscl") # use pR2( ) function to calculate McFadden statistics for model eval
typePR = pR2(typeLogit)
typePR
unloadPkg("pscl")
datage <- dat[ ,c('Type','Gender', 'MaturitySize', 'FurLength', 'Vaccinated', 'PhotoAmt', 'VideoAmt', 'AdoptionSpeed') ]
datage$puppy = NaN
datage$puppy[dat$Age <= 3] = 1
datage$puppy[dat$Age > 3] = 0
datage$puppy = as.factor(datage$puppy)
puppies = subset(datage, datage$puppy == 1)
older = subset(datage, datage$puppy ==0)
puppy_proportion = nrow(puppies) * 100/nrow(dat)
loadPkg("bestglm")
datage$y = datage$puppy
datage <- subset(datage, -c('puppy'))
loadPkg("bestglm")
datage$y = datage$puppy
datage <- subset(datage, ! datage$puppy)
logit_pups <- bestglm(Xy =datage, family = binomial, IC = "AIC", method = "exhaustive")
loadPkg("bestglm")
datage$y = datage$puppy
datage <- subset(datage, ! datage$puppy)
datage <- na.omit(datage)
logit_pups <- bestglm(Xy =datage, family = binomial, IC = "AIC", method = "exhaustive")
loadPkg("bestglm")
loadPkg("leaps")
datage$y = datage$puppy
datage <- subset(datage, ! datage$puppy)
datage <- na.omit(datage)
logit_pups <- bestglm(Xy = datage, family = binomial, IC = "AIC", method = "exhaustive")
loadPkg("bestglm")
loadPkg("leaps")
datage$y <- datage$puppy
datage <- subset(datage, ! datage$puppy)
datage <- na.omit(datage)
logit_pups <- bestglm(Xy = datage, family = binomial, IC = "AIC", method = "exhaustive")
loadPkg("bestglm")
loadPkg("leaps")
datage$y <- datage$puppy
datage <- na.omit(datage)
logit_pups <- bestglm(Xy = datage, family = binomial, IC = "AIC", method = "exhaustive")
# some of common options (and the defaults) are:
# include=T, eval=T, echo=T, results='hide'/'asis'/'markup',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right',
library(ezids)
# knitr::opts_chunk$set(warning = F, results = "markup", message = F)
knitr::opts_chunk$set(warning = F, results = "hide", message = F, echo = F)
options(scientific=T, digits = 3)
# options(scipen=9, digits = 3)
# ‘scipen’: integer. A penalty to be applied when deciding to print numeric values in fixed or exponential notation.  Positive values bias towards fixed and negative towards scientific notation: fixed notation will be preferred unless it is more than ‘scipen’ digits wider.
# use scipen=999 to prevent scientific notation at all times
library("corrplot")
library("ezids")
library("gtsummary")
library('ggridges')
library('viridis')
library('wesanderson')
library('gridExtra')
library('leaps')
library('vtable')
## Loading data
data = read.csv('datafile.csv')
initialrows = nrow(data)
data$AdoptionSpeed <- factor(data$AdoptionSpeed, order=T, levels = c(0,1,2,3,4))
# converting the data types we want - categorical
data$Type = as.factor(data$Type)
data$MaturitySize = as.factor(data$MaturitySize)
data$FurLength = as.factor(data$FurLength)
data$Vaccinated = as.factor(data$Vaccinated)
data$Gender = as.factor(data$Gender)
# Only looking at profiles with 1 animal
data = subset(data, data$Quantity == 1)
data = subset(data, ! data$AdoptionSpeed == 4)
# Only pulling the columns we want to look at
dat = data[c('Type', 'Age', 'Gender', 'MaturitySize', 'FurLength', 'Vaccinated', 'PhotoAmt','VideoAmt', 'AdoptionSpeed')]
summary(dat)
# Adding random values
#dat$ASnum = NaN
#dat$ASnum[dat$AdoptionSpeed == 0] = 0
#dat$ASnum[dat$AdoptionSpeed == 1] = floor(runif(sum(dat$AdoptionSpeed == 1), 1, 8))
#dat$ASnum[dat$AdoptionSpeed == 2] = floor(runif(sum(dat$AdoptionSpeed == 2), 8, 31))
#dat$ASnum[dat$AdoptionSpeed == 3] = floor(runif(sum(dat$AdoptionSpeed == 3), 31, 91))
#dat$ASnum[dat$AdoptionSpeed == 4] = 100 -- this line isn't necessary because we exclude animals that have this adoption speed
summary(dat)
datclean = dat[, c('Age', 'Gender', 'MaturitySize', 'FurLength', 'Vaccinated', 'PhotoAmt', 'VideoAmt', 'AdoptionSpeed')]
datclean$y = dat[, c('Type')]
loadPkg("bestglm")
res.bestglm <- bestglm(Xy = datclean, family = binomial,
IC = "AIC",                 # Information criteria for
method = "exhaustive")
summary(res.bestglm)
res.bestglm$BestModels
summary(res.bestglm$BestModels)
unloadPkg("bestglm")
unloadPkg("leaps") # leaps is required by bestglm, thus cannot be unloaded before bestglm
typeLogit <- glm(Type ~ Age + Gender + MaturitySize + FurLength + Vaccinated + AdoptionSpeed + PhotoAmt, data = dat, family = "binomial")
xkabledply(typeLogit, title = paste("Logistic Regression :", format(formula(typeLogit)) ))
loadPkg("ResourceSelection") # function hoslem.test( ) for logit model evaluation
typeHoslem = hoslem.test(dat$Type, fitted(typeLogit)) # Hosmer and Lemeshow test, a chi-squared test
typeHoslem
unloadPkg("ResourceSelection") # function hoslem.test( ) for logit model evaluation
loadPkg("pROC") # receiver operating characteristic curve, gives the diagnostic ability of a binary classifier system as its discrimination threshold is varied. The curve is on sensitivity/recall/true-positive-rate vs false_alarm/false-positive-rate/fall-out.
prob=predict(typeLogit, type = "response" )
dat$prob=prob
h <- roc(Type~prob, data=dat)
plot(h)
auc(h)
loadPkg("pscl") # use pR2( ) function to calculate McFadden statistics for model eval
typePR = pR2(typeLogit)
typePR
unloadPkg("pscl")
datage <- dat[ ,c('Type','Gender', 'MaturitySize', 'FurLength', 'Vaccinated', 'PhotoAmt', 'VideoAmt', 'AdoptionSpeed') ]
datage$puppy = NaN
datage$puppy[dat$Age <= 3] = 1
datage$puppy[dat$Age > 3] = 0
datage$puppy = as.factor(datage$puppy)
puppies = subset(datage, datage$puppy == 1)
older = subset(datage, datage$puppy ==0)
puppy_proportion = nrow(puppies) * 100/nrow(dat)
loadPkg("bestglm")
loadPkg("leaps")
datage$y <- datage$puppy
datage <- na.omit(datage)
logit_pups <- bestglm(Xy = datage, family = binomial, IC = "AIC", method = "exhaustive")
loadPkg("bestglm")
loadPkg("leaps")
datage$y <- datage$puppy
datage <- na.omit(datage)
logit_pups <- bestglm(Xy = datage, family = binomial, IC = "AIC", method = "exhaustive")
summary(logit_pups)
logit_pups$BestModels
summary(logit_pups$BestModels)
