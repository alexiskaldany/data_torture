---
title: "PetFinder Adoption Final Paper"
author: "Group 3: Data Torturers (Alexis Kaldany, Sahara Ensley, Yixi Liang, Kaiyuan Liang)"
date: "`r Sys.Date()`"
output: 
  rmdformats::robobook:
  html_document:
    code_folding: hide
    number_sections: false
    toc: yes
    toc_depth: 3
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: '3'
---

```{r setup, include=FALSE}
# some of common options (and the defaults) are: 
# include=T, eval=T, echo=T, results='hide'/'asis'/'markup',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right', 
library(ezids)
# knitr::opts_chunk$set(warning = F, results = "markup", message = F)
knitr::opts_chunk$set(warning = F, results = "hide", message = F, echo = F)
options(scientific=T, digits = 3) 
# options(scipen=9, digits = 3) 
# ‘scipen’: integer. A penalty to be applied when deciding to print numeric values in fixed or exponential notation.  Positive values bias towards fixed and negative towards scientific notation: fixed notation will be preferred unless it is more than ‘scipen’ digits wider.
# use scipen=999 to prevent scientific notation at all times
```

- Loading data and libraries
```{r}
library("corrplot")
library("ezids")
library("gtsummary")
library('ggridges')
library('viridis')
library('wesanderson')
library('gridExtra')
library('leaps')
library('vtable')
## Loading data
data = read.csv('datafile.csv')

initialrows = nrow(data)

data$AdoptionSpeed <- factor(data$AdoptionSpeed, order=T, levels = c(0,1,2,3,4))

# converting the data types we want - categorical
data$Type = as.factor(data$Type)
data$MaturitySize = as.factor(data$MaturitySize)
data$FurLength = as.factor(data$FurLength)
data$Vaccinated = as.factor(data$Vaccinated)
data$Gender = as.factor(data$Gender)

# Only looking at profiles with 1 animal
data = subset(data, data$Quantity == 1)
data = subset(data, ! data$AdoptionSpeed == 4)

# Only pulling the columns we want to look at
dat = data[c('Type', 'Age', 'Gender', 'MaturitySize', 'FurLength', 'Vaccinated', 'PhotoAmt','VideoAmt', 'AdoptionSpeed')]
summary(dat)

# Adding random values
#dat$ASnum = NaN
#dat$ASnum[dat$AdoptionSpeed == 0] = 0
#dat$ASnum[dat$AdoptionSpeed == 1] = floor(runif(sum(dat$AdoptionSpeed == 1), 1, 8))
#dat$ASnum[dat$AdoptionSpeed == 2] = floor(runif(sum(dat$AdoptionSpeed == 2), 8, 31))
#dat$ASnum[dat$AdoptionSpeed == 3] = floor(runif(sum(dat$AdoptionSpeed == 3), 31, 91))
#dat$ASnum[dat$AdoptionSpeed == 4] = 100 -- this line isn't necessary because we exclude animals that have this adoption speed

summary(dat)
```

#Kaiyuan's section




# Yixi's section




# Sahara's section
# SMART QUESTION: Can the type of animal be classified from the adoption profile?

Starting with Logistic Regression. Trying out feature selection first.

```{r}
# creating a cleaned dataset without the animal type
datclean = dat[, c('Age', 'Gender', 'MaturitySize', 'FurLength', 'Vaccinated', 'PhotoAmt', 'VideoAmt', 'AdoptionSpeed')]

# labeling the target variable appropriately
datclean$y = dat[, c('Type')]
```

```{r}
loadPkg("bestglm")

# feature selection
res.bestglm <- bestglm(Xy = datclean, family = binomial,
            IC = "AIC",
            method = "exhaustive")
summary(res.bestglm) # printing the summary
res.bestglm$BestModels
summary(res.bestglm$BestModels)

unloadPkg("bestglm") 
```

The best model based off this feature selection is every feature except video amount.

```{r}
typeLogit <- glm(y ~ Age + Gender + MaturitySize + FurLength + Vaccinated + AdoptionSpeed + PhotoAmt, data = datclean, family = "binomial")
xkabledply(typeLogit, title = paste("Logistic Regression :", format(formula(typeLogit)) ))
```

```{r}
loadPkg("ResourceSelection") # function hoslem.test( ) for logit model evaluation
typeHoslem = hoslem.test(datclean$y, fitted(typeLogit)) # Hosmer and Lemeshow test, a chi-squared test
typeHoslem
unloadPkg("ResourceSelection") # function hoslem.test( ) for logit model evaluation
```


```{r}
loadPkg("pROC") # receiver operating characteristic curve, gives the diagnostic ability of a binary classifier system as its discrimination threshold is varied. The curve is on sensitivity/recall/true-positive-rate vs false_alarm/false-positive-rate/fall-out.
prob=predict(typeLogit, type = "response" )
datclean$prob=prob
h <- roc(y~prob, data=datclean)
plot(h)
auc(h)
```

Not a great model. Only at 0.7.

```{r}
loadPkg("pscl") # use pR2( ) function to calculate McFadden statistics for model eval
typePR = pR2(typeLogit)
typePR
unloadPkg("pscl") 
```

According to the McFadden score only `r format(round(typePR['McFadden'] * 100), 0)`% of the variance in Type is explained by this model, so incredibly low.

Lets try a KNN model next. First the variables need to be returned to integers to pass into the model and the numerical features need to be scaled. First I'm using all the features and running a search for the optimal K.

```{r}
loadPkg("gmodels")

# reloading the original dataframe to cancel all the factor variables
knndat = read.csv('datafile.csv')
knndat = subset(knndat, knndat$Quantity == 1)
knndat = subset(knndat, ! knndat$AdoptionSpeed == 4)

knndat = knndat[c('Type', 'Age', 'Gender', 'MaturitySize', 'FurLength', 'Vaccinated', 'PhotoAmt','VideoAmt', 'AdoptionSpeed')]

scaledknn = as.data.frame(scale(knndat[c(2, 7, 8)], center = TRUE, scale = TRUE)) # only scaling the numerical values
scaledknn[c('Type', 'Gender', 'MaturitySize', 'FurLength', 'Vaccinated', 'AdoptionSpeed')] = knndat[c(1, 3, 4, 5, 6, 9)]

#sampling for train and test
set.seed(1000)
knn_sample <- sample(2, nrow(scaledknn), replace=TRUE, prob=c(0.7, 0.3))

train <- scaledknn[knn_sample==1, 1:3, 5:9]
test <- scaledknn[knn_sample==2, 1:3, 5:9]

typeknn.trainLabel = scaledknn[knn_sample==1, 4]
typeknn.testLabel = scaledknn[knn_sample==2, 4]

ResultDf = data.frame( k=numeric(0), Total.Accuracy= numeric(0), row.names = NULL )

for (kval in 3:20) {
  tpred <- knn(train = train, test = test, cl=typeknn.trainLabel, k=kval)
  cross <- CrossTable(typeknn.testLabel, tpred, prop.chisq = FALSE)
  cm = confusionMatrix(tpred, reference = as.factor(typeknn.testLabel)) # from caret library
  
  cmaccu = cm$overall['Accuracy']
  cmt = data.frame(k=kval, Total.Accuracy = cmaccu, row.names = NULL ) # initialize a row of the metrics 
  ResultDf = rbind(ResultDf, cmt)
}

ResultDf[which.max(ResultDf$Total.Accuracy),]
```

Okay could be worse. Let's try and remove some features.

```{r}

knndat2 = read.csv('datafile.csv')
knndat2 = subset(knndat2, knndat2$Quantity == 1)
knndat2 = subset(knndat2, ! knndat2$AdoptionSpeed == 4)
knndat2 = knndat2[c('Type', 'Age', 'MaturitySize', 'FurLength', 'Vaccinated', 'PhotoAmt', 'AdoptionSpeed')]

scaledknn2 = as.data.frame(scale(knndat2[c(2, 6)], center = TRUE, scale = TRUE)) # only scaling the numerical values
scaledknn2[c('Type', 'MaturitySize', 'FurLength', 'Vaccinated', 'AdoptionSpeed')] = knndat2[c(1, 3, 4, 5, 7)]

#sampling for train and test
set.seed(1000)
knn_sample2 <- sample(2, nrow(scaledknn2), replace=TRUE, prob=c(0.7, 0.3))

train2 <- scaledknn2[knn_sample2==1, 1:2, 4:7]
test2 <- scaledknn2[knn_sample2==2, 1:2, 4:7]

typeknn2.trainLabel = scaledknn2[knn_sample2==1, 3]
typeknn2.testLabel = scaledknn2[knn_sample2==2, 3]

ResultDf2 = data.frame( k=numeric(0), Total.Accuracy= numeric(0), row.names = NULL )

for (kval in 3:20) {
  tpred <- knn(train = train2, test = test2, cl=typeknn2.trainLabel, k=kval)
  cross <- CrossTable(typeknn2.testLabel, tpred, prop.chisq = FALSE)
  print( paste("k = ", kval) )
  cm = confusionMatrix(tpred, reference = as.factor(typeknn2.testLabel)) # from caret library
  cmaccu = cm$overall['Accuracy']
  cmt = data.frame(k=kval, Total.Accuracy = cmaccu, row.names = NULL ) # initialize a row of the metrics 
  ResultDf2 = rbind(ResultDf2, cmt)
}

ResultDf2[which.max(ResultDf2$Total.Accuracy),]

```

Not quite as good as the first model so we'll stick with that one.

# Alexis's section

- SMART Question:  Can puppies/kittens be identified based on their adoption profile?

- Creating section specific variables

```{r}
datage <- dat[ ,c('Type','Gender', 'MaturitySize', 'FurLength', 'Vaccinated', 'PhotoAmt', 'VideoAmt', 'AdoptionSpeed') ]
datage$puppy = NaN
datage$puppy[dat$Age <= 3] = 1
datage$puppy[dat$Age > 3] = 0
datage$puppy = as.factor(datage$puppy)
puppies = subset(datage, datage$puppy == 1)
older = subset(datage, datage$puppy ==0)
puppy_proportion = nrow(puppies) * 100/nrow(dat)
```

- To answer the SMART question, let us consider the general problem. There is a categorical dependent variable, and a mixture of numerical and categorical independent variables. A Logistic Regression makes a great deal of sense in this situation. Potentially KNN or classification-tree model.

As `r puppy_proportion` percent of the pets are puppies, there is a very good balance for our dependent variable. 

## Logistic Model

- Starting off with a full model, excluding Age as it would perfectly predict `r datage$puppy`

```{r}
loadPkg("bestglm")
loadPkg("leaps")
datage$y <- datage$puppy
datage <- na.omit(datage)
logit_pups <- bestglm(Xy = datage, family = binomial, IC = "AIC", method = "exhaustive")
summary(logit_pups)
logit_pups$BestModels
summary(logit_pups$BestModels)
```

## Classification Tree

# Conclusion