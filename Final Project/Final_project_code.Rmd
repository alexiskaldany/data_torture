---
title: "PetFinder Adoption Final Paper"
author: "Group 3: Data Torturers (Alexis Kaldany, Sahara Ensley, Yixi Liang, Kaiyuan Liang)"
date: "`r Sys.Date()`"
output: 
  rmdformats::robobook:
  html_document:
    code_folding: hide
    number_sections: false
    toc: yes
    toc_depth: 3
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: '3'
---

```{r setup, include=FALSE}
# some of common options (and the defaults) are: 
# include=T, eval=T, echo=T, results='hide'/'asis'/'markup',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right', 
library(ezids)
#knitr::opts_chunk$set(warning = F, results = "markup", message = F, echo = F)
knitr::opts_chunk$set(warning = F, results = "hide", message = F)
options(scientific=T, digits = 3) 
# options(scipen=9, digits = 3) 
# ‘scipen’: integer. A penalty to be applied when deciding to print numeric values in fixed or exponential notation.  Positive values bias towards fixed and negative towards scientific notation: fixed notation will be preferred unless it is more than ‘scipen’ digits wider.
# use scipen=999 to prevent scientific notation at all times
```

- Loading data and libraries
```{r}
#library("corrplot")
#library("ezids")
#library("gtsummary")
#library('ggridges')
#library('viridis')
#library('wesanderson')
#library('gridExtra')
#library('leaps')
#library('vtable')
#library('pscl')  

## Loading data
data = read.csv('datafile.csv',encoding = "UTF-8")

initialrows = nrow(data)

data$AdoptionSpeed <- factor(data$AdoptionSpeed, order=T, levels = c(0,1,2,3,4))

# converting the data types we want - categorical
data$Type = as.factor(data$Type)
data$MaturitySize = as.factor(data$MaturitySize)
data$FurLength = as.factor(data$FurLength)
data$Vaccinated = as.factor(data$Vaccinated)
data$Gender = as.factor(data$Gender)

# Only looking at profiles with 1 animal
data = subset(data, data$Quantity == 1)
data = subset(data, ! data$AdoptionSpeed == 4)

# Only pulling the columns we want to look at
dat = data[c('Type', 'Age', 'Gender', 'MaturitySize', 'FurLength', 'Vaccinated', 'PhotoAmt','VideoAmt', 'AdoptionSpeed')]
summary(dat)

# Adding random values
#dat$ASnum = NaN
#dat$ASnum[dat$AdoptionSpeed == 0] = 0
#dat$ASnum[dat$AdoptionSpeed == 1] = floor(runif(sum(dat$AdoptionSpeed == 1), 1, 8))
#dat$ASnum[dat$AdoptionSpeed == 2] = floor(runif(sum(dat$AdoptionSpeed == 2), 8, 31))
#dat$ASnum[dat$AdoptionSpeed == 3] = floor(runif(sum(dat$AdoptionSpeed == 3), 31, 91))
#dat$ASnum[dat$AdoptionSpeed == 4] = 100 -- this line isn't necessary because we exclude animals that have this adoption speed

summary(dat)
```

# Background EDA

We're using the same dataset as from the midterm assignment. The data comes from Kaggle (https://www.kaggle.com/c/petfinder-adoption-prediction/data) and includs almost 15,000 observations of 23 variables. Each observation is an adoption profile on PetFinder in Malaysia. We chose to keep `r length(dat)` features, as well as discarding any profile that contained more than one animal, and any animal that did not get adopted in the first 100 days. At the end of these cleaning measures we end up with `r nrow(dat)` observations of the `r length(dat)` features. Initially we transformed the categorical dependent variable (adoption speed) into a continuous numerical variable. For the sake of this project we are keeping it as a categorical variable for some of our analyses.

As a refresher on the basic features of the dataset we can look at the distribution of the various variables.

First here is our dependent variable Adoption Speed, plotted by number of occurences since it is categorical.
```{r histogram of AdoptionSpeed}
loadPkg("ggplot2")
#Histogram
ggplot(data=dat, aes(AdoptionSpeed)) + 
  geom_bar(breaks=seq(0, 4, by=1),
                 col="red",
                 aes(fill=..count..)) +
  labs(title="AdoptionSpeed of pets", x = "AdoptionSpeed") + 
  scale_fill_gradient("Count", low="green", high="red")

```

We can also look at the other numerical features.
```{r Age}
tmpDatAge = dat
tmpDatAge$Age = as.numeric(dat$Age)

ggplot(data=tmpDatAge, aes(Age)) + 
  geom_histogram(breaks=seq(0, 100, by=5),
                 col="red",
                 aes(fill=..count..)) +
  labs(title="Histogram of Age of pets", x="Age(in months)") + 
  scale_fill_gradient("Count", low="green", high="red")
#Boxplot
ggplot(data = tmpDatAge,aes(y = Age))+
  geom_boxplot() + 
  geom_boxplot( colour="orange", fill="#7777cc", outlier.colour="red", outlier.shape=8, outlier.size=4) +
  labs(title="Age boxplot using `ggplot`",x="", y = "Age")

#Q-Q plot
qqnorm(tmpDatAge$Age, main="Q-Q plot of Age of pets", ylab = "Age(in months)",col="blue")
qqline(tmpDatAge$Age)
```

```{r PhotoAmt}
tmpPhotoAmt = dat
tmpPhotoAmt$PhotoAmt = as.numeric(tmpPhotoAmt$PhotoAmt)

ggplot(data=tmpPhotoAmt, aes(PhotoAmt)) + 
  geom_histogram(breaks=seq(0, 30, by=2),
                 col="red",
                 aes(fill=..count..)) +
  labs(title="Histogram of PhotoAmt of pets") + 
  scale_fill_gradient("Count", low="green", high="red")

#Boxplot
ggplot(data = tmpPhotoAmt,aes(y = PhotoAmt))+
  geom_boxplot() + 
  geom_boxplot( colour="orange", fill="#7777cc", outlier.colour="red", outlier.shape=8, outlier.size=4) +
  labs(title="PhotoAmt boxplot using `ggplot`",x="", y = "Number of Photoes")

#Q-Q plot
qqnorm(tmpPhotoAmt$PhotoAmt, main="Q-Q plot of PhotoAmt of pets", ylab = "PhotoAmt",col="blue")
qqline(tmpPhotoAmt$PhotoAmt)
```

Next we can see the distributions of the categorical variables.

```{r Type}
dog = nrow(dat[dat$Type=="1",])
cat = nrow(dat[dat$Type=="2",])
totalamount = dog+cat

percentDog = format(dog/totalamount * 100, digits = 4)
percentCat = format(cat/totalamount * 100, digits = 4)

Prop <- c(dog,cat)
# Prepare a color palette. Here with R color brewer:
library(RColorBrewer)
myPalette <- brewer.pal(5, "RdYlGn") 

# You can change the border of each area with the classical parameters:
pie(Prop , labels = c(paste("Dog: ",percentDog,"%"), paste("Cat: ",percentCat,"%")),
    main = "Pie plot of Type of pets", border="white", col=myPalette )
```
The second is `Gender`. There are two genders: `Male` and `Female`.  
```{r Gender}
#pie plot
male = nrow(dat[dat$Gender=="1",])
female = nrow(dat[dat$Gender=="2",])
percentMale = format(male/(male+female) * 100, digits = 4)
percentFemale = format(female/(male+female) * 100, digits = 4)
Prop <- c(male,female)
# Prepare a color palette. Here with R color brewer:
library(RColorBrewer)
myPalette <- brewer.pal(3, "Pastel1") 

# You can change the border of each area with the classical parameters:
pie(Prop , labels = c(paste("Male: ", percentMale,"%"),paste("Female: ",percentFemale,"%")), main = "Pie plot of Gender", border="white", col=myPalette )
```
The third is `MaturitySize`. There are four levels, namely `Small`,` Medium`, `Large`, and `ExtraLarge`.    
```{r MaturitySize}
small = nrow(dat[dat$MaturitySize=="1",])
medium = nrow(dat[dat$MaturitySize=="2",])
large = nrow(dat[dat$MaturitySize=="3",])
extraLarge = nrow(dat[dat$MaturitySize=="4",])
totalamount = small+medium+large+extraLarge

percentSmall = format(small/totalamount * 100, digits = 4)
percentMedium = format(medium/totalamount * 100, digits = 4)
percentLarge = format(large/totalamount * 100, digits = 4)
percentExtraLarge = format(extraLarge/totalamount * 100, digits = 4)
#pie plot
Prop <- c(small,medium,large,extraLarge)
# Prepare a color palette. Here with R color brewer:
library(RColorBrewer)
myPalette <- brewer.pal(8, "Spectral") 

# You can change the border of each area with the classical parameters:
pie(Prop , labels = c(paste("Small: ",percentSmall,"%"), paste("Medium: ",percentMedium,"%"), paste("Large: ",percentLarge,"%"), paste("Extra Large: ",percentExtraLarge,"%")), main = "Pie plot of MaturitySize", border="white", col=myPalette )

```
The fourth is `FurLength`. There are three levels, namely `Short`, `Medium`, and `Long`.  
```{r FurLength}

short = nrow(dat[dat$FurLength=="1",])
medium = nrow(dat[dat$FurLength=="2",])
long = nrow(dat[dat$FurLength=="3",])
totalamount = short+medium+long

percentShort = format(short/totalamount * 100, digits = 4)
percentMedium = format(medium/totalamount * 100, digits = 4)
percentLong = format(long/totalamount * 100, digits = 4)


#pie plot
Prop <- c(short,medium,long)
# Prepare a color palette. Here with R color brewer:
library(RColorBrewer)
myPalette <- brewer.pal(3, "Set2") 

# You can change the border of each area with the classical parameters:
pie(Prop , labels = c(paste("Short: ",percentShort,"%"), paste("Medium: ",percentMedium,"%"), paste("Long: ", percentLong,"%")), main = "Pie plot of FurLength", border="white", col=myPalette )
```
The fifth is `Vaccinated`. There are three levels, namely `Vaccinated`, `Unvaccinated`, and `Not Specified`.    
```{r Vaccinated}
vaccinatedYes = nrow(dat[dat$Vaccinated=="1",])
vaccinatedNo = nrow(dat[dat$Vaccinated=="2",])
vaccinatedNotSure = nrow(dat[dat$Vaccinated=="3",])
totalamount = vaccinatedYes+vaccinatedNo+vaccinatedNotSure

percentVaccinatedYes = format(vaccinatedYes/totalamount * 100, digits = 4)
percentVaccinatedNo = format(vaccinatedNo/totalamount * 100, digits = 4)
percentVaccinatedNotSure = format(vaccinatedNotSure/totalamount * 100, digits = 4)

#pie plot
Prop <- c(vaccinatedYes,vaccinatedNo,vaccinatedNotSure)
# Prepare a color palette. Here with R color brewer:
library(RColorBrewer)
myPalette <- brewer.pal(11,"Paired") 

# You can change the border of each area with the classical parameters:
pie(Prop , labels = c(paste("Vaccinated: ",percentVaccinatedYes, "%"), paste("Unvaccinated: ",percentVaccinatedNo, "%"), paste("Not Specified: ",percentVaccinatedNotSure, "%")), main = "Pie plot of Vaccinated", border="white", col=myPalette )
```

After this we did some EDA to see what features affected adoption speed. We initially had a numerical dependent variable so we converted it to a continuous numerical feature. We then ran ANOVAs on a number of the features against the now numerical adoption speed. We discovered that if we disregarded the asumption of equal variance, every feature significantly impacted adoption speed. 

```{r}
numericaldat = dat
numericaldat$ASnum = NaN
numericaldat$ASnum[numericaldat$AdoptionSpeed == 0] = 0
numericaldat$ASnum[numericaldat$AdoptionSpeed == 1] = floor(runif(sum(numericaldat$AdoptionSpeed == 1), 1, 8))
numericaldat$ASnum[numericaldat$AdoptionSpeed == 2] = floor(runif(sum(numericaldat$AdoptionSpeed == 2), 8, 31))
numericaldat$ASnum[numericaldat$AdoptionSpeed == 3] = floor(runif(sum(numericaldat$AdoptionSpeed == 3), 31, 91))
dogs = subset(numericaldat, numericaldat$Type == 1) # only the dogs
cats = subset(numericaldat, numericaldat$Type == 2) # only the cats
# 2 sample t-test
dc_t = t.test(dogs$ASnum, cats$ASnum)
dc_t
male = subset(numericaldat, numericaldat$Gender == 1) # only the male dogs
female = subset(numericaldat, numericaldat$Gender == 2) # only the female dogs
# 2 sample t-test
mf_t = t.test(male$ASnum, female$ASnum)
mf_t
# anova on size
anova_size = anova(aov(data = numericaldat, ASnum ~ MaturitySize))
anova_size
# anova for fur length
anova_fur = anova(aov(data = numericaldat, ASnum ~ FurLength))
anova_fur
# vaccination anova
anova_vac = anova(aov(data = numericaldat, ASnum ~ Vaccinated))
anova_vac
```

#SMART QUESTION: What is the probability that a large, female, vaccinated dog would get adopted quickly (adoption speed of 0 and 1). 
```{r}
##data preparation
new_dat = dat[c('Type',  'Gender', 'MaturitySize', 'Vaccinated', 'AdoptionSpeed')]
xkabledply(summary(new_dat))
```
```{r}
library(ggplot2)
ggplot(data=new_dat, aes(AdoptionSpeed)) + 
  geom_bar(breaks=seq(0, 4, by=1),
                 col="red",
                 aes(fill=..count..)) +
  labs(title="AdoptionSpeed of pets", x = "AdoptionSpeed") + 
  scale_fill_gradient("Count", low="lightblue", high="#FF9999")

```

```{r}
###group adoption speed 0 and 1
levels(new_dat$AdoptionSpeed)[levels(new_dat$AdoptionSpeed)==1] <-0
summary(new_dat)

```


```{r}
###group adoption speed 3 and 4
levels(new_dat$AdoptionSpeed)[levels(new_dat$AdoptionSpeed)==4] <-3
summary(new_dat)

```


```{r}
###group adoption speed 2 and 3
levels(new_dat$AdoptionSpeed)[levels(new_dat$AdoptionSpeed)==3] <-2
xkabledply(summary(new_dat))

```
```{r}
levels(new_dat$AdoptionSpeed) <- c("0", "1")
summary(new_dat)

```



```{r}
ggplot(data=new_dat, aes(AdoptionSpeed)) + 
  geom_bar(breaks=seq(0, 4, by=1),
                 col="red",
                 aes(fill=..count..)) +
  labs(title="AdoptionSpeed of pets", x = "AdoptionSpeed") + 
  scale_fill_gradient("Count", low="lightblue", high="#FF9999")
```

```{r}
logit <- glm(AdoptionSpeed ~ Type + MaturitySize + Vaccinated + Gender, data = new_dat, family = "binomial")
summary(logit)

```
```{r}
loadPkg("regclass")
xkabledply(confusion_matrix(logit), title = "Confusion matrix from Logit Model" )
```
```{r}
loadPkg("ResourceSelection")
LogitHoslem = hoslem.test(new_dat$AdoptionSpeed,fitted(logit)) # Hosmer and Lemeshow test, a chi-squared test
unloadPkg("ResourceSelection")
LogitHoslem
```


```{r}
loadPkg("pROC")
prob=predict(logit, type = "response" )
new_dat$prob=prob
h <- roc(AdoptionSpeed~prob, data=new_dat)
#auc(h) 
plot(h, main = "ROC curve of model")
```



```{r}
preds <- with(new_dat,data.frame(Type=as.factor(1),MaturitySize=as.factor(3),Gender=as.factor(2),Vaccinated=as.factor(1)))

d3 <- cbind(preds, predict(logit, newdata = preds, type = "link",se = TRUE))

d3 <- within(d3, {
    PredictedProb <- plogis(fit)
    LL <- plogis(fit - (1.96 * se.fit))
    UL <- plogis(fit + (1.96 * se.fit))
})

d3

```


# SMART QUESTION: Does animal Type, Gender, MaturitySize, FurLength, and Vaccination status influence the adoption speed significantly, and what is the best model (Logistic Regression, Knn) when considering these variables?
```{r}
dataTGMFV = dat[, c('Age','Type','Gender','MaturitySize','FurLength','Vaccinated','PhotoAmt','VideoAmt','AdoptionSpeed')]
dataTGMFV$AdoptionSpeed[dat$AdoptionSpeed == 0|dat$AdoptionSpeed == 1] = 0
dataTGMFV$AdoptionSpeed[dat$AdoptionSpeed == 2|dat$AdoptionSpeed == 3|dat$AdoptionSpeed == 4 ] = 1
# dataTGMFV$AdoptionSpeed = droplevels(dataTGMFV$AdoptionSpeed)
dataTGMFV$AdoptionSpeed = factor(dataTGMFV$AdoptionSpeed)
str(dataTGMFV)
```

### Exhaustive search  

```{r}
#This is essentially best fit 
reg.best10 <- regsubsets(AdoptionSpeed~. , data = dataTGMFV, nvmax = 10, nbest = 1, method = "exhaustive")  # leaps::regsubsets() - Model selection by exhaustive (default) search, forward or backward stepwise, or sequential replacement
#The plot will show the Adjust R^2 when using the variables across the bottom
plot(reg.best10, scale = "adjr2", main = "Adjusted R^2")
plot(reg.best10, scale = "r2", main = "R^2")
# In the "leaps" package, we can use scale=c("bic","Cp","adjr2","r2")
plot(reg.best10, scale = "bic", main = "BIC")
plot(reg.best10, scale = "Cp", main = "Cp")
summary(reg.best10)
```


```{r}
# petFeaturetable1 = glm(AdoptionSpeed ~ Age+Type+Gender+MaturitySize+FurLength+Vaccinated+PhotoAmt+VideoAmt, data = dataTGMFV, family = "binomial")
petFeaturetableAll = glm(AdoptionSpeed ~Age+Type+Gender+MaturitySize+FurLength+Vaccinated+PhotoAmt, data = dataTGMFV, family = "binomial")
# petFeaturetableR2 = glm(AdoptionSpeed ~ Type+Gender+MaturitySize+FurLength+Vaccinated, data = dataTGMFV, family = "binomial")
# petFeaturetable = glm(AdoptionSpeed ~Vaccinated, data = dataTGMFV, family = "binomial")
summary(petFeaturetableAll)
```
```{r, results='markup'}
loadPkg("regclass")
loadPkg("ModelMetrics")
xkabledply( confusion_matrix(petFeaturetableAll), title = "Confusion matrix from Logit Model" )
pred_ = predict(petFeaturetableAll, dataTGMFV[1:8], type="response")
unloadPkg("regclass")
confusionMatrix( pred_, as.factor(dataTGMFV$AdoptionSpeed))
unloadPkg("ModelMetrics")
```
```{r}
loadPkg("ResourceSelection") # function hoslem.test( ) for logit model evaluation
petLogitHoslem = hoslem.test(dataTGMFV$AdoptionSpeed, fitted(petFeaturetableAll)) # Hosmer and Lemeshow test, a chi-squared test
unloadPkg("ResourceSelection")
petLogitHoslem
```
```{r}
loadPkg("pROC") # receiver operating characteristic curve, gives the diagnostic ability of a binary classifier system as its discrimination threshold is varied. The curve is on sensitivity/recall/true-positive-rate vs false_alarm/false-positive-rate/fall-out.
prob=predict(petFeaturetableAll, type = "response" )
dataTGMFV$prob=prob
h <- roc(AdoptionSpeed~prob, data=dataTGMFV)
#auc(h) # area-under-curve prefer 0.8 or higher.
plot(h)
```
#### McFadden

```{r}
loadPkg("pscl") # use pR2( ) function to calculate McFadden statistics for model eval
petLogitpr2 = pR2(petFeaturetableAll)
petLogitpr2
unloadPkg("pscl") 
```
With the McFadden value of `r petLogitpr2['McFadden']`, which is analogous to the coefficient of determination $R^2$, only about 2% of the variations in y is explained by the explanatory variables in the model. 

```{r}
featureClean = dat[ , c('Age','Type','Gender','MaturitySize','FurLength','Vaccinated','PhotoAmt','VideoAmt')]
featureClean$y = dataTGMFV$AdoptionSpeed # copy Holiday column and call it 'y'
#convert some columns into factos as appropriate

featureClean$y <- ifelse(featureClean$y == 1,TRUE,FALSE)
featureClean$y = factor(featureClean$y)
str(featureClean)
```

```{r}
loadPkg("leaps")
reg.leaps <- regsubsets(y~., data = featureClean, nbest = 1, method = "exhaustive")  # leaps, 
plot(reg.leaps, scale = "adjr2", main = "Adjusted R^2")
plot(reg.leaps, scale = "bic", main = "BIC")
plot(reg.leaps, scale = "Cp", main = "Cp")
```

```{r}
loadPkg("bestglm")
res.bestglm <- bestglm(Xy = featureClean, family = binomial,
            IC = "AIC",                 # Information criteria for
            method = "exhaustive")
summary(res.bestglm)
res.bestglm$BestModels
summary(res.bestglm$BestModels)
unloadPkg("bestglm")
unloadPkg("leaps")
```
#### KNN
```{r}
loadPkg("gmodels")
loadPkg("FNN")
loadPkg("caret") # confusionMatrix
#first we want to scale the data so KNN will operate correctly
knnDataTGMFV = dataTGMFV[1:9]
knnDataTGMFV$Type = as.numeric(knnDataTGMFV$Type)
knnDataTGMFV$Gender = as.numeric(knnDataTGMFV$Gender)
knnDataTGMFV$MaturitySize = as.numeric(knnDataTGMFV$MaturitySize)
knnDataTGMFV$FurLength = as.numeric(knnDataTGMFV$FurLength)
knnDataTGMFV$Vaccinated = as.numeric(knnDataTGMFV$Vaccinated)
# knnDataTGMFV$AdoptionSpeed = dat$AdoptionSpeed
str(knnDataTGMFV)

scaledPet <- as.data.frame(scale(knnDataTGMFV[1:8], center = TRUE, scale = TRUE))
#We also need to create test and train data sets, we will do this slightly differently by using the sample function. The 2 says create 2 data sets essentially, replacement means we can reset the random sampling across each vector and the probability gives sample the weight of the splits, 2/3 for train, 1/3 for test. 
set.seed(1000)
pet_sample <- sample(2, nrow(scaledPet), replace=TRUE, prob=c(0.67, 0.33))
#We then just need to use the new variable to create the test/train outputs, selecting the first five rows as they are the numeric data in the pet data set and we want to predict AdoptionSpeed 
pet_training <- scaledPet[pet_sample==1, 1:8]
pet_test <- scaledPet[pet_sample==2, 1:8]
```
```{r}
#Now we need to create our 'Y' variables or labels need to input into the KNN function
pet.trainLabels <- knnDataTGMFV[pet_sample==1, 9]
pet.testLabels <- knnDataTGMFV[pet_sample==2, 9]
```

```{r}
loadPkg("gmodels")
loadPkg('FNN')
#So now we will deploy our model 
pet_pred <- knn(train = pet_training, test = pet_test, cl=pet.trainLabels, k=7)
```
```{r}
petPREDCross <- CrossTable(pet.testLabels, pet_pred, prop.chisq = FALSE)
#Looks like we got all but three correct, not bad
```
```{r}
loadPkg("gmodels")
loadPkg("FNN")
loadPkg("caret")
confusionMatrix

# Loop thru different k values

# create an empty dataframe to store the results from confusion matrices
ResultDf = data.frame( k=numeric(0), Total.Accuracy= numeric(0), row.names = NULL )

for (kval in 3:21) {
  pet_pred <- knn(train = pet_training, test = pet_test, cl=pet.trainLabels, k=kval)
  petPREDCross <- CrossTable(pet.testLabels, pet_pred, prop.chisq = FALSE)
  print( paste("k = ", kval) )
  petPREDCross
  # 
  cm = caret::confusionMatrix(pet_pred, reference = pet.testLabels ) # from caret library
  # print.confusionMatrix(cm)
  # 
  cmaccu = cm$overall['Accuracy']
  print( paste("Total Accuracy = ", cmaccu ) )
  # print("Other metrics : ")
  # print(cm$byClass)
  # 
  cmt = data.frame(k=kval, Total.Accuracy = cmaccu, row.names = NULL ) # initialize a row of the metrics 
  # cmt = cbind( cmt, data.frame( t(cm$byClass) ) ) # the dataframe of the transpose, with k valued added in front
  ResultDf = rbind(ResultDf, cmt)
  print( xkabledply(   as.matrix(cm), title = paste("ConfusionMatrix for k = ",kval ) ) )
  print( xkabledply(data.frame(cm$byClass), title=paste("k = ",kval)) )
}
```
```{r}
xkabledply(ResultDf[ResultDf$k%%2 == 1,])
```

# SMART QUESTION: Can the type of animal be classified from the adoption profile?

Given that the type of animal is a categorical variable this is a classification problem. The first model we can try is a Logistic Regression model. First we need a new clean dataset with the features we want and a renamed target variable for the feature selection.

```{r, results = 'markup'}
# creating a cleaned dataset without the animal type
datclean = dat[, c('Age', 'Gender', 'MaturitySize', 'FurLength', 'Vaccinated', 'PhotoAmt', 'VideoAmt', 'AdoptionSpeed')]

# labeling the target variable appropriately
datclean$y = dat[, c('Type')]
str(datclean)
```

Now we can run the feature selection.
```{r, results='markup'}
loadPkg("bestglm")

# feature selection
res.bestglm <- bestglm(Xy = datclean, family = binomial,
            IC = "AIC",
            method = "exhaustive")
#summary(res.bestglm) # printing the summary
res.bestglm$BestModels
#summary(res.bestglm$BestModels)
unloadPkg("bestglm") 
```

The best model based off this feature selection is every feature except video amount. Now we can make that model.

```{r, results='markup'}
typeLogit <- glm(y ~ Age + Gender + MaturitySize + FurLength + Vaccinated + AdoptionSpeed + PhotoAmt, data = datclean, family = "binomial")
xkabledply(typeLogit, title = paste("Logistic Regression : Type ~ age+gender+size+fur+vaccinated+AdoptSpd+photos"))
```

```{r}
loadPkg("regclass")
loadPkg("ModelMetrics")
xkabledply( confusion_matrix(typeLogit), title = "Type Confusion matrix from Logit Model" )
typep = predict(typeLogit, datclean, type="response")
#confusionMatrix(typep, datclean$y)
unloadPkg("regclass")
```


There are a number of significant values for these coefficients. But let's look at other metrics to get a sense of the effectiveness of this model.

```{r, results='markup'}
loadPkg("ResourceSelection") # function hoslem.test( ) for logit model evaluation
typeHoslem = hoslem.test(datclean$y, fitted(typeLogit)) # Hosmer and Lemeshow test, a chi-squared test
typeHoslem
unloadPkg("ResourceSelection") # function hoslem.test( ) for logit model evaluation
```

The GOF value is very low which suggests that the model isn't a great fit. But we can look closer at this with an ROC plot.

```{r, results='markup'}
loadPkg("pROC") # receiver operating characteristic curve, gives the diagnostic ability of a binary classifier system as its discrimination threshold is varied. The curve is on sensitivity/recall/true-positive-rate vs false_alarm/false-positive-rate/fall-out.
prob=predict(typeLogit, type = "response" )
datclean$prob=prob
h <- roc(y~prob, data=datclean)
plot(h)
#auc(h)
```

The ROC plot confirms that this is not a great model. The AUC value is 0.7, not at our bar of 0.8. Let's check one more measure.

```{r, results = 'markup'}
loadPkg("pscl") # use pR2( ) function to calculate McFadden statistics for model eval
typePR = pR2(typeLogit)
typePR
unloadPkg("pscl") 
```

According to the McFadden score only `r format(round(typePR['McFadden'] * 100), 0)`% of the variance in Type is explained by this model, this is incredibly low. Clearly the logistic regression model is not great at classifying type, or type is not decodeable from the profile.

Lets try a KNN model next. First the variables need to be returned to integers to pass into the model and the numerical features need to be scaled. First we're using all the features and running a search for the optimal K. The search for K went over values 3 - 20.

```{r}
loadPkg("gmodels")
loadPkg("FNN")
loadPkg("caret")

# reloading the original dataframe to cancel all the factor variables
knndat = read.csv('datafile.csv')
knndat = subset(knndat, knndat$Quantity == 1)
knndat = subset(knndat, ! knndat$AdoptionSpeed == 4)

knndat = knndat[c('Type', 'Age', 'Gender', 'MaturitySize', 'FurLength', 'Vaccinated', 'PhotoAmt','VideoAmt', 'AdoptionSpeed')]

scaledknn = as.data.frame(scale(knndat[c(2, 7, 8)], center = TRUE, scale = TRUE)) # only scaling the numerical values
scaledknn[c('Type', 'Gender', 'MaturitySize', 'FurLength', 'Vaccinated', 'AdoptionSpeed')] = knndat[c(1, 3, 4, 5, 6, 9)]

#sampling for train and test
set.seed(1000)
knn_sample <- sample(2, nrow(scaledknn), replace=TRUE, prob=c(0.7, 0.3))

train <- scaledknn[knn_sample==1, 1:3, 5:9]
test <- scaledknn[knn_sample==2, 1:3, 5:9]

typeknn.trainLabel = scaledknn[knn_sample==1, 4]
typeknn.testLabel = scaledknn[knn_sample==2, 4]

ResultDf = data.frame( k=numeric(0), Total.Accuracy= numeric(0), row.names = NULL )

for (kval in 3:20) {
  tpred <- knn(train = train, test = test, cl=typeknn.trainLabel, k=kval)
  cross <- CrossTable(typeknn.testLabel, tpred, prop.chisq = FALSE)
  cm = caret::confusionMatrix(tpred, as.factor(typeknn.testLabel)) # from caret library
  
  cmaccu = cm$overall['Accuracy']
  cmt = data.frame(k=kval, Total.Accuracy = cmaccu, row.names = NULL ) # initialize a row of the metrics 
  ResultDf = rbind(ResultDf, cmt)
}

ResultDf[which.max(ResultDf$Total.Accuracy),]
```

According to the KNN model with all features included, the best K value is 8 and it produces an accuracy of `r ResultDf[which.max(ResultDf$Total.Accuracy),]$Total.Accuracy`.

Let's try and remove some features. We removed features by logic. For example gender is something that is consistent between types and video amount was removed in the logistic model so we removed it for this test to see if it improved anything. Again we ran through 18 possible K values from 3-20.

```{r}
loadPkg("gmodels")
loadPkg("FNN")
loadPkg("caret")

knndat2 = read.csv('datafile.csv')
knndat2 = subset(knndat2, knndat2$Quantity == 1)
knndat2 = subset(knndat2, ! knndat2$AdoptionSpeed == 4)
knndat2 = knndat2[c('Type', 'Age', 'Gender', 'MaturitySize', 'FurLength', 'Vaccinated', 'PhotoAmt', 'AdoptionSpeed')]

scaledknn2 = as.data.frame(scale(knndat2[c(2, 6)], center = TRUE, scale = TRUE)) # only scaling the numerical values
scaledknn2[c('Type', 'MaturitySize', 'FurLength', 'Vaccinated', 'AdoptionSpeed')] = knndat2[c(1, 3, 4, 5, 7)]

#sampling for train and test
set.seed(1000)
knn_sample2 <- sample(2, nrow(scaledknn2), replace=TRUE, prob=c(0.7, 0.3))

train2 <- scaledknn2[knn_sample2==1, 1:2, 4:7]
test2 <- scaledknn2[knn_sample2==2, 1:2, 4:7]

typeknn2.trainLabel = scaledknn2[knn_sample2==1, 3]
typeknn2.testLabel = scaledknn2[knn_sample2==2, 3]

ResultDf2 = data.frame( k=numeric(0), Total.Accuracy= numeric(0), row.names = NULL )

for (kval in 3:20) {
  tpred <- knn(train = train2, test = test2, cl=typeknn2.trainLabel, k=kval)
  cross <- CrossTable(typeknn2.testLabel, tpred, prop.chisq = FALSE)
  print( paste("k = ", kval) )
  cm = caret::confusionMatrix(tpred, reference = as.factor(typeknn2.testLabel)) # from caret library
  cmaccu = cm$overall['Accuracy']
  cmt = data.frame(k=kval, Total.Accuracy = cmaccu, row.names = NULL ) # initialize a row of the metrics 
  ResultDf2 = rbind(ResultDf2, cmt)
}

ResultDf2[which.max(ResultDf2$Total.Accuracy),]

```

Slightly better than the first model, so lets stick with this one.


```{r}
tpred <- knn(train = train2, test = test2, cl=typeknn2.trainLabel, k=10)
cross <- CrossTable(typeknn2.testLabel, tpred, prop.chisq = FALSE)
cm = caret::confusionMatrix(tpred, reference = as.factor(typeknn2.testLabel)) # from caret library
cmaccu = cm$overall['Accuracy']

cross
cm
```

However, when we look closer at the predictions we can see that it just over predicted dogs. The balanced accuracy value dropped by a couple percentage points. At the end of all of this we're basically just above chance in the predictions for both models which leads us to the conclusion that the type of animal can't be predicted based on the adoption profile.

# SMART Question:  Can puppies/kittens be identified based on their adoption profile?

```{r}
datage <- dat[ ,c('Type','Gender', 'MaturitySize', 'FurLength', 'Vaccinated', 'PhotoAmt', 'VideoAmt', 'AdoptionSpeed') ]
datage$puppy = NaN
datage$puppy[dat$Age <= 3] = 1
datage$puppy[dat$Age > 3] = 0
datage$puppy = as.factor(datage$puppy)
puppies = subset(datage, datage$puppy == 1)
older = subset(datage, datage$puppy ==0)
puppy_proportion = nrow(puppies) * 100/nrow(dat)
```

- To answer the SMART question, let us consider the general problem. There is a categorical dependent variable, and a mixture of numerical and categorical independent variables. A Logistic Regression makes a great deal of sense in this situation. Potentially KNN or classification-tree model.

As `r puppy_proportion` percent of the pets are puppies, there is a very good balance for our dependent variable. 

## Logistic Model

- Starting off with a full model, excluding Age as it would perfectly predict Puppy.

```{r}
loadPkg("bestglm")
loadPkg("leaps")

datage$y <- datage$puppy
datage <- datage[, c('Type', 'Gender', 'MaturitySize', 'FurLength', 'Vaccinated', 'PhotoAmt', 'VideoAmt', 'AdoptionSpeed', 'y')]
datage <- na.omit(datage)
# using bestglm as it has feature selection built in

logit_pups <- bestglm(Xy = datage, family = binomial, IC = "AIC", method = "exhaustive")
summary(logit_pups)
unloadPkg("bestglm") 
```


Summary of Logistic Model Feature Selection
```{r results='markup'}
logit_pups$BestModels
summary(logit_pups$BestModels)
```

Feature Selection indicates everything except PhotoAmt should be used to generate best logistic model.

Creating Best Logistic Model
```{r results='markup'}
pup_logit <- glm(y ~ Type + Gender + MaturitySize + FurLength + Vaccinated + VideoAmt + AdoptionSpeed, data = datage, family = "binomial")
xkabledply(pup_logit, title = paste("Logistic Regression : Puppy ~ type +gender+size+fur+vaccinated+AdoptSpd+videos"))
```

Confusion Matrix for Logistic Model:

```{r}
loadPkg("regclass")
xkabledply( confusion_matrix(pup_logit), title = "Confusion matrix from Logit Model" )
```

```{r results='markup'}
#loadPkg("caret") 
#cm_puppy_logi = confusionMatrix(pup_logit, type = "class", reference = datage$y )
#print('Overall: ')
#cm_puppy_logi$overall
#print('Class: ')
#cm_puppy_logi$byClass
#unloadPkg("caret")
```


Checking Model Effectiveness
```{r}
loadPkg("ResourceSelection") # function hoslem.test( ) for logit model evaluation
ageHoslem = hoslem.test(datage$y, fitted(pup_logit)) # Hosmer and Lemeshow test, a chi-squared test
ageHoslem
unloadPkg("ResourceSelection") # function hoslem.test( ) for logit model evaluation
```

-As the p-value is very low, indicating the recommended logistic model is not a good fit.


```{r results='markup'}
loadPkg("pROC")
prob=predict(pup_logit, type = "response" )
datage$prob=prob
h <- roc(y~prob, data=datage)
plot(h)
#auc(h)
```

-The shape is decent, but the score of .761 is below the recommended 0.8 thresh-hold, but indicates a better fit than the Hosmer-Lemeshow test would indicate. 

```{r, results = 'markup'}
loadPkg("pscl") # use pR2( ) function to calculate McFadden statistics for model eval
typePR = pR2(pup_logit)
typePR
unloadPkg("pscl") 
```

The McFadden score of `r format(round(typePR['McFadden'] * 100), 0)`% is pretty low.


Lets see if a classification tree can give a better score. 

## Classification Tree

```{r}
loadPkg("rpart")
datage <- datage[, c('Type', 'Gender', 'MaturitySize', 'FurLength', 'Vaccinated', 'PhotoAmt', 'VideoAmt', 'AdoptionSpeed', 'y')]
puppy_tree <- rpart(y ~ Type + Gender + MaturitySize + FurLength + Vaccinated + PhotoAmt + VideoAmt + AdoptionSpeed ,data = datage, method="class", control = list(maxdepth = 20))
puppy_tree_vac_adopt <- rpart(y ~ Vaccinated+ AdoptionSpeed ,data = datage, method="class", control = list(maxdepth = 20))
```

```{r results='markup'}
#printcp(puppy_tree) # display the results 
printcp(puppy_tree_vac_adopt)
```

```{r results='markup'}
plotcp(puppy_tree) # visualize cross-validation results 
```

```{r results='markup'}
summary(puppy_tree) # detailed summary of splits
#summary(puppy_tree_vac_adopt)
```

Confusion Matrix for Classification Tree

```{r}
loadPkg("caret") 
cm_puppy_tree = caret::confusionMatrix( predict(puppy_tree, type = "class"), reference = datage$y )
print('Overall: ')
cm_puppy_tree$overall
print('Class: ')
cm_puppy_tree$byClass
unloadPkg("caret")
xkabledply(cm_puppy_tree$table, "confusion matrix")
```


Plot Tree

```{r}
loadPkg("rpart.plot")
loadPkg("rattle")
fancyRpartPlot(puppy_tree)
```


# Conclusion

- Best Model Accuracy for the 4 SMART Questions:

Targeted Prediction Accuracy: .675
Adoption Speed Prediction: Logistic Model, Accuracy .65, McFadden = .027
Pet Type Prediction Accuracy: Logistic Model, .677, McFadden = .097
Age Type Prediction Accuracy: Logistic Model, .695, McFadden = .163